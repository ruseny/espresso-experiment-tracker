{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "768d861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from mimesis import Person, Address, Datetime, Text\n",
    "from mimesis.locales import Locale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d6f1e1",
   "metadata": {},
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a9d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_users = {\n",
    "    \"id\" : [], \n",
    "    \"username\": [],\n",
    "    \"password_hash\": [],\n",
    "    \"email\": [],\n",
    "    \"first_name\": [],\n",
    "    \"last_name\": [],\n",
    "    \"date_of_birth\": [],\n",
    "    \"street_address\": [],\n",
    "    \"city\": [],\n",
    "    \"postal_code\": [],\n",
    "    \"registration_datetime\": [],\n",
    "    \"user_type\": [],\n",
    "}\n",
    "\n",
    "N_USERS = 12\n",
    "\n",
    "for id in range(1, N_USERS + 1):\n",
    "    person_gen = Person(Locale.DE, seed = 42 + id)\n",
    "    address_gen = Address(Locale.DE, seed = 42 + id)\n",
    "    date_gen = Datetime(Locale.DE, seed = 42 + id)\n",
    "\n",
    "    dict_users[\"id\"].append(id)\n",
    "    dict_users[\"username\"].append(person_gen.username())\n",
    "    dict_users[\"password_hash\"].append(person_gen.password(hashed = True))\n",
    "    dict_users[\"email\"].append(person_gen.email())\n",
    "    dict_users[\"first_name\"].append(person_gen.first_name())\n",
    "    dict_users[\"last_name\"].append(person_gen.last_name())\n",
    "    dict_users[\"date_of_birth\"].append(person_gen.birthdate(min_year = 1960, max_year = 2000).strftime(\"%Y-%m-%d\"))\n",
    "    dict_users[\"street_address\"].append(address_gen.address())\n",
    "    dict_users[\"city\"].append(address_gen.city())\n",
    "    dict_users[\"postal_code\"].append(address_gen.postal_code())\n",
    "    dict_users[\"registration_datetime\"].append(date_gen.datetime(start = 2023, end = 2024).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    dict_users[\"user_type\"].append(\"test\")\n",
    "\n",
    "df_users = pd.DataFrame(dict_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8412c",
   "metadata": {},
   "source": [
    "## Coffee machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6098c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coffee_machines = pd.DataFrame(\n",
    "    columns = [\n",
    "        \"id\", \n",
    "        \"manufacturer\",\n",
    "        \"model_name\",\n",
    "        \"model_name_add\",\n",
    "        \"model_specification\",\n",
    "        \"product_identifier\",\n",
    "        \"pump_pressure_bar\",\n",
    "        \"pump_type\",\n",
    "        \"water_temp_control\",\n",
    "        \"pid_control\",\n",
    "        \"boiler_type\",\n",
    "        \"portafilter_diam_mm\"\n",
    "    ], \n",
    "    data = [\n",
    "        (1, 'DeLonghi', 'Dedica', '', 'Black', 'EC685.BK', 15, 'vibrating', 'no', '', 'single boiler', 51),\n",
    "        (2, 'Sage/Breville', 'Barista', 'Pro', 'Brushed Stainless Steel', 'SES878BSS4EEU1', 15, 'vibrating', 'yes', 'automatic', 'dual boiler', 54),\n",
    "        (3, 'Sage/Breville', 'Oracle', 'Touch', 'Matte Black', 'SES990BSS4EEU1', 9, 'vibrating', 'yes', 'programmable', 'dual boiler', 58),\n",
    "        (4, 'Lelit', 'Bianca', '', 'Steel', 'LE-PL162T V3', 10, 'rotary pump', 'yes', 'programmable', 'dual boiler ', 58),\n",
    "        (5, 'DeLonghi', 'La Specialista', 'Arte', 'Yellow', 'EC9155.YE', 15, 'vibrating', 'no', '', 'single boiler', 51),\n",
    "        (6, 'Sage/Breville', 'Barista', 'Express', 'Black truffle', 'SES875BTR2EEU1', 9, 'vibrating', 'yes', 'automatic', 'dual boiler', 54),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e7998",
   "metadata": {},
   "source": [
    "## Grinders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4bf9e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grinders = pd.DataFrame(\n",
    "    columns = [\n",
    "        \"id\",\n",
    "        \"manufacturer\",\n",
    "        \"model_name\",\n",
    "        \"model_name_add\",\n",
    "        \"model_specification\",\n",
    "        \"product_identifier\",\n",
    "        \"operation_type\",\n",
    "        \"burr_shape\",\n",
    "        \"burr_diameter_mm\",\n",
    "        \"burr_material\",\n",
    "        \"min_setting\",\n",
    "        \"max_setting\",\n",
    "        \"min_espresso_range\",\n",
    "        \"max_espresso_range\",\n",
    "        \"single_dose\"\n",
    "    ],\n",
    "    data = [\n",
    "        (1, 'Baratza', 'Encore', 'ESP', 'Black', '495W-230V-F', 'electric', '', pd.NA, '', 0, 40, 0, 20, 'no'), \n",
    "        (2, 'Sage/Breville', 'The Smart Grinder', 'Pro', 'Brushed Stainless Steel', 'SCG820BSS4EEU1', 'electric', '', pd.NA, '', 1, 60, 1, 30, 'no'), \n",
    "        (3, 'Eureka', 'Mignon', 'Oro', 'Black', 'EAN 8059519339448', 'electric', '', pd.NA, '', 0, 30, 0, 8, 'no'), \n",
    "        (4, 'Hario', 'Skerton', 'Plus', 'Schwarz', 'B01LXZACFB', 'manual', '', pd.NA, '', pd.NA, pd.NA, pd.NA, pd.NA, 'no'), \n",
    "        (5, 'DeLonghi', 'Dedica', 'Grinder', 'Steel, Silver ', 'KG520.M', 'electric', '', pd.NA, '', 1, 18, pd.NA, pd.NA, 'no')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03af70",
   "metadata": {},
   "source": [
    "## Equipment ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439bcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_equipment = {\n",
    "    \"id\": [],\n",
    "    \"user_id\": [],\n",
    "    \"equipment_type\": [],\n",
    "    \"coffee_machine_id\": [],\n",
    "    \"grinder_id\": [],\n",
    "    \"purchase_date\": [],\n",
    "    \"purchased_from\": [], \n",
    "    \"purchase_price_eur\": []\n",
    "}\n",
    "\n",
    "N_COFFEE_MACHINES = 6\n",
    "N_GRINDERS = 3\n",
    "\n",
    "dict_equipment[\"id\"] = np.arange(1, N_USERS*2 + 1).tolist()\n",
    "dict_equipment[\"user_id\"] = np.tile(range(1, N_USERS + 1), 2).tolist()\n",
    "dict_equipment[\"equipment_type\"] = np.repeat([\"coffee_machine\", \"grinder\"], N_USERS).tolist()\n",
    "dict_equipment[\"coffee_machine_id\"] = np.concatenate((\n",
    "    np.repeat(range(1, N_COFFEE_MACHINES + 1), N_USERS // N_COFFEE_MACHINES),\n",
    "    np.repeat(np.nan, N_USERS)\n",
    ")).tolist()\n",
    "dict_equipment[\"grinder_id\"] = np.concatenate((\n",
    "    np.repeat(np.nan, N_USERS), \n",
    "    np.tile(range(1, N_GRINDERS + 1), N_USERS // N_GRINDERS)\n",
    ")).tolist()\n",
    "\n",
    "for i in range(1, N_USERS*2 + 1):\n",
    "    date_gen = Datetime(Locale.DE, seed = 42 + i)\n",
    "    random.seed(42 + i)\n",
    "    dict_equipment[\"purchase_date\"].append(date_gen.date(start = 2018, end = 2024).strftime(\"%Y-%m-%d\"))\n",
    "    dict_equipment[\"purchased_from\"].append(random.choice([\"Amazon\", \"eBay\", \"Mediamarkt\", \"Roastmarket\", \"Local Store\"]))\n",
    "    dict_equipment[\"purchase_price_eur\"].append(np.nan)\n",
    "\n",
    "df_equipment = pd.DataFrame(dict_equipment)\n",
    "df_equipment[\"coffee_machine_id\"] = df_equipment[\"coffee_machine_id\"].astype(pd.Int64Dtype())\n",
    "df_equipment[\"grinder_id\"] = df_equipment[\"grinder_id\"].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25870bfc",
   "metadata": {},
   "source": [
    "## User defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caab9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_defaults = {\n",
    "    \"user_id\" : [], \n",
    "    \"coffee_machine_id\": [],\n",
    "    \"grinder_id\": [],\n",
    "    \"basket_pressurized\": [],\n",
    "    \"basket_shot_size\": [],\n",
    "    \"portafilter_spout\": [],\n",
    "    \"wdt_used\": [],\n",
    "    \"tamping_method\": [],\n",
    "    \"tamping_weight_kg\": [],\n",
    "    \"leveler_used\": [],\n",
    "    \"puck_screen_used\": [],\n",
    "    \"puck_screen_thickness_mm\": [],\n",
    "    \"setup_name\": []\n",
    "}\n",
    "\n",
    "dict_defaults[\"user_id\"] = np.arange(1, N_USERS + 1).tolist()\n",
    "dict_defaults[\"coffee_machine_id\"] = np.repeat(range(1, N_COFFEE_MACHINES + 1), N_USERS // N_COFFEE_MACHINES).tolist()\n",
    "dict_defaults[\"grinder_id\"] = np.tile(range(1, N_GRINDERS + 1), N_USERS // N_GRINDERS).tolist()\n",
    "dict_defaults[\"basket_pressurized\"] = [\"no\" for _ in range(N_USERS)]\n",
    "dict_defaults[\"basket_shot_size\"] = [\"double\" for _ in range(N_USERS)]\n",
    "dict_defaults[\"portafilter_spout\"] = [\"double\" for _ in range(N_USERS)]\n",
    "np.random.seed(42)\n",
    "dict_defaults[\"wdt_used\"] = np.random.choice([\"yes\", \"no\"], N_USERS, p=[0.5, 0.5]).tolist()\n",
    "dict_defaults[\"tamping_method\"] = [\"manual\" for _ in range(N_USERS)]\n",
    "dict_defaults[\"tamping_weight_kg\"] = [pd.NA for _ in range(N_USERS)]\n",
    "dict_defaults[\"leveler_used\"] = np.random.choice([\"yes\", \"no\"], N_USERS, p=[0.3, 0.7]).tolist()\n",
    "dict_defaults[\"puck_screen_used\"] = np.random.choice([\"yes\", \"no\"], N_USERS, p=[0.5, 0.5]).tolist()\n",
    "dict_defaults[\"puck_screen_thickness_mm\"] = [pd.NA for _ in range(N_USERS)]\n",
    "for i in dict_defaults[\"user_id\"]:\n",
    "    users_name = df_users.loc[df_users[\"id\"] == i, \"first_name\"].values[0]\n",
    "    dict_defaults[\"setup_name\"].append(f\"{users_name}'s Setup\")\n",
    "\n",
    "df_defaults = pd.DataFrame(dict_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac39ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_defaults.loc[df_defaults[\"coffee_machine_id\"].isin([1, 6]), \"portafilter_spout\"] = \"bottomless\"\n",
    "n_puck_screens = df_defaults[\"puck_screen_used\"].value_counts().get(\"yes\", 0)\n",
    "df_defaults.loc[df_defaults[\"puck_screen_used\"] == \"yes\", \"puck_screen_thickness_mm\"] = np.random.choice([1.0, 1.7, 2.0], n_puck_screens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dde98f",
   "metadata": {},
   "source": [
    "## Coffee varieties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b53413",
   "metadata": {},
   "source": [
    "### Single origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec81bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roast_rating_10 = np.array([6, 8, 10])\n",
    "roast_relative = roast_rating_10 / 10\n",
    "\n",
    "intensity_rating_10 = np.array([5, 7, 9])\n",
    "intensity_relative = intensity_rating_10 / 10\n",
    "\n",
    "acidity_rating_10 = np.array([2])\n",
    "acidity_relative = acidity_rating_10 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "987d3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.array(np.meshgrid(\n",
    "    roast_relative,\n",
    "    intensity_relative,\n",
    "    acidity_relative,\n",
    ")).T.reshape(-1, 3)\n",
    "\n",
    "df_variety_so = pd.DataFrame(grid, \n",
    "    columns=[\n",
    "        'roast_level', \n",
    "        'intensity', \n",
    "        'acidity']\n",
    ")\n",
    "\n",
    "df_variety_so[\"origin_type\"] = \"single origin\"\n",
    "df_variety_so[\"arabica_ratio\"] = 1.0\n",
    "\n",
    "for i in range(len(df_variety_so)):\n",
    "    random.seed(42 + i)\n",
    "    origin_name = random.choice([\"Colombia\", \"Brazil\", \"Honduras\", \"Peru\", \"Mexico\", \"Gueatemala\"])\n",
    "    df_variety_so.at[i, \"origin\"] = origin_name\n",
    "\n",
    "    if origin_name == \"Brazil\":\n",
    "        locale = Locale.PT_BR\n",
    "    else:\n",
    "        locale = Locale.ES_MX\n",
    "    \n",
    "    text_gen = Text(locale, seed=42 + i)\n",
    "    df_variety_so.at[i, \"name\"] = f\"{text_gen.color()} {text_gen.word()}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c526a2",
   "metadata": {},
   "source": [
    "### Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "477e9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "roast_rating_10 = np.array([6, 8, 10])\n",
    "roast_relative = roast_rating_10 / 10\n",
    "\n",
    "intensity_rating_10 = np.array([8, 10])\n",
    "intensity_relative = intensity_rating_10 / 10\n",
    "\n",
    "acidity_rating_10 = np.array([2, 4])\n",
    "acidity_relative = acidity_rating_10 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9cfc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.array(np.meshgrid(\n",
    "    roast_relative,\n",
    "    intensity_relative,\n",
    "    acidity_relative,\n",
    ")).T.reshape(-1, 3)\n",
    "\n",
    "df_variety_blend = pd.DataFrame(grid,\n",
    "    columns=[\n",
    "        'roast_level', \n",
    "        'intensity', \n",
    "        'acidity']\n",
    ")\n",
    "\n",
    "df_variety_blend[\"origin_type\"] = \"blend\"\n",
    "df_variety_blend[\"arabica_ratio\"] = np.random.choice([0.7, 0.8], len(df_variety_blend), p=[0.4, 0.6])\n",
    "\n",
    "for i in range(len(df_variety_blend)):\n",
    "    random.seed(2025 + i)\n",
    "    origin_name = random.choice([\"Latin America\", \"Unspecified\"])\n",
    "    df_variety_blend.at[i, \"origin\"] = origin_name\n",
    "\n",
    "    if origin_name == \"Latin America\":\n",
    "        locale = Locale.ES_MX\n",
    "    else:\n",
    "        locale = Locale.IT\n",
    "    \n",
    "    text_gen = Text(locale, seed = 2025 + i)\n",
    "    df_variety_blend.at[i, \"name\"] = f\"{text_gen.color()} {text_gen.word()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4948e82",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971fe5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variety = pd.concat([df_variety_so, df_variety_blend], ignore_index=True)\n",
    "\n",
    "df_variety[\"decaffeinated\"] = \"no\"\n",
    "\n",
    "producer_list = [\n",
    "    \"Bean Masters\", \n",
    "    \"Coffee Artisans\", \n",
    "    \"Brewed Perfection\", \n",
    "    \"Roast Revolution\", \n",
    "    \"Espresso Excellence\"\n",
    "]\n",
    "\n",
    "df_variety[\"producer\"] = np.random.choice(producer_list, len(df_variety))\n",
    "\n",
    "flavor_list = [\n",
    "    \"chocolate\", \n",
    "    \"dark chocolate\",\n",
    "    \"caramel\", \n",
    "    \"citrus\", \n",
    "    \"berry\", \n",
    "    \"fruity\",\n",
    "    \"nutty\", \n",
    "    \"hazelnut\",\n",
    "    \"vanilla\",\n",
    "    \"floral\", \n",
    "    \"spicy\", \n",
    "    \"smoky\"\n",
    "]\n",
    "\n",
    "for i in range(len(df_variety)):\n",
    "    random.seed(42 + i)\n",
    "    n_flavors = random.randint(1, 3)\n",
    "    flavors = random.sample(flavor_list, n_flavors)\n",
    "    df_variety.at[i, \"flavor_notes\"] = \", \".join(flavors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00a0440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variety = df_variety.reset_index(drop = True)\n",
    "df_variety = df_variety.reset_index(names = \"id\")\n",
    "df_variety[\"id\"] = df_variety[\"id\"] + 1\n",
    "\n",
    "df_variety = df_variety[[\n",
    "    \"id\", \n",
    "    \"producer\", \n",
    "    \"name\",\n",
    "    \"origin\",\n",
    "    \"origin_type\",\n",
    "    \"arabica_ratio\",\n",
    "    \"roast_level\",\n",
    "    \"intensity\",\n",
    "    \"acidity\",\n",
    "    \"flavor_notes\", \n",
    "    \"decaffeinated\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a2cde",
   "metadata": {},
   "source": [
    "## Coffee purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f45d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_purchase = {\n",
    "    \"user_id\": [],\n",
    "    \"variety_id\": [],\n",
    "    \"purchase_date\": [],\n",
    "    \"purchased_from\": [],\n",
    "    \"weight_kg\": [],\n",
    "    \"price_per_kg_eur\": []\n",
    "}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(len(df_variety) * 4):\n",
    "    date_gen = Datetime(Locale.DE, seed = 42 + i)\n",
    "\n",
    "    user_id = (i % N_USERS) + 1\n",
    "    variety_id = (i % len(df_variety)) + 1\n",
    "    purchase_date = date_gen.date(start = 2025).strftime(\"%Y-%m-%d\")\n",
    "    purchased_from = random.choice([\"Amazon\", \"Roastmarket\", \"Edeka\", \"Rewe\", \"Local roaster\"])\n",
    "    weight_kg = np.random.choice([0.25, 0.5, 1, 1.5], p = [0.3, 0.2, 0.4, 0.1])\n",
    "    price_per_kg_eur = round(np.random.normal(25, 2), 2)\n",
    "\n",
    "    dict_purchase[\"user_id\"].append(user_id)\n",
    "    dict_purchase[\"variety_id\"].append(variety_id)\n",
    "    dict_purchase[\"purchase_date\"].append(purchase_date)\n",
    "    dict_purchase[\"purchased_from\"].append(purchased_from)\n",
    "    dict_purchase[\"weight_kg\"].append(weight_kg)\n",
    "    dict_purchase[\"price_per_kg_eur\"].append(price_per_kg_eur)\n",
    "\n",
    "df_purchase = pd.DataFrame(dict_purchase)\n",
    "df_purchase = df_purchase.reset_index(names = \"id\")\n",
    "df_purchase[\"id\"] = df_purchase[\"id\"] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a00ec",
   "metadata": {},
   "source": [
    "## Espresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fcebcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roast_rating_10 = np.array([6, 8, 10])\n",
    "roast_relative = roast_rating_10 / 10\n",
    "\n",
    "grind_settings_20 = np.array([5, 6, 8, 10, 12, 15, 18])\n",
    "grind_relative = grind_settings_20 / 20\n",
    "\n",
    "dose_gr = np.array([16, 17, 17.5, 18, 18.5, 19, 20])\n",
    "dose_relative = (dose_gr - 15) / 5\n",
    "\n",
    "extr_sec = np.array([20, 23, 25, 27, 30])\n",
    "extr_relative = (extr_sec - 20) / 20 + 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a083839",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.array(np.meshgrid(roast_relative, grind_relative, dose_relative, extr_relative)).T.reshape(-1, 4)\n",
    "extr_ratio_raw = 2*grid[:, 1] - grid[:, 0] - grid[:, 2]\n",
    "extr_ratio_scaled = ((extr_ratio_raw - np.min(extr_ratio_raw)) / (np.max(extr_ratio_raw) - np.min(extr_ratio_raw))) * 2 + 1\n",
    "extr_ratio_time_adj = extr_ratio_scaled * grid[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0a61d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_nparray = np.array(np.meshgrid(roast_relative, grind_relative, dose_gr, extr_sec)).T.reshape(-1, 4)\n",
    "baseline_nparray = np.column_stack((baseline_nparray, extr_ratio_time_adj))\n",
    "df_baseline = pd.DataFrame(baseline_nparray, columns=['roast', 'grind', 'dose', 'extr_sec', 'extr_ratio'])\n",
    "for col in df_baseline:\n",
    "    df_baseline[col] = df_baseline[col].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4046a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_from_extr_ratio(extr_ratio):\n",
    "    if extr_ratio >= 1.5 and extr_ratio <= 2:\n",
    "        return 3\n",
    "    elif extr_ratio < 1.5 and extr_ratio >= 1:\n",
    "        return 2\n",
    "    elif extr_ratio > 2 and extr_ratio <= 2.75:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df_baseline[\"sampling_weight\"] = df_baseline[\"extr_ratio\"].apply(get_weight_from_extr_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc120f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coffee_sample(\n",
    "        baseline = df_baseline,\n",
    "        selection_col = \"roast\", \n",
    "        selection_crit = 0.8,\n",
    "        sample_size = 50, \n",
    "        weight_col = \"sampling_weight\",\n",
    "        random_state = 42,\n",
    "        extr_ratio_col = \"extr_ratio\",\n",
    "        extr_ratio_shift = 0, \n",
    "        extr_ratio_sd = 0.1,\n",
    "        dose_col = \"dose\",\n",
    "        yield_shift = 0,\n",
    "        yield_sd = 1,\n",
    "):\n",
    "    new_df = baseline[baseline[selection_col] == selection_crit].sample(\n",
    "        n = sample_size,\n",
    "        replace = True,\n",
    "        weights = weight_col,\n",
    "        random_state = random_state\n",
    "    )\n",
    "    new_df = new_df.drop(columns=[weight_col])\n",
    "    new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    new_df[extr_ratio_col] = new_df[extr_ratio_col] + np.random.normal(\n",
    "        loc = extr_ratio_shift,\n",
    "        scale = extr_ratio_sd,\n",
    "        size = new_df.shape[0]\n",
    "    )\n",
    "\n",
    "    new_df[\"yield_gr\"] = new_df[dose_col] * new_df[extr_ratio_col]\n",
    "    new_df[\"yield_gr\"] = new_df[\"yield_gr\"] + np.random.normal(\n",
    "        loc = yield_shift,\n",
    "        scale = yield_sd,\n",
    "        size = new_df.shape[0]\n",
    "    )\n",
    "    new_df[\"yield_gr\"] = new_df[\"yield_gr\"].round(1)\n",
    "\n",
    "    new_df = new_df.rename(columns={\n",
    "        \"grind\": \"grind_setting\",\n",
    "        \"dose\": \"dose_gr\",\n",
    "        \"extr_sec\": \"extraction_time_sec\"\n",
    "    })\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b7bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14058/3956816567.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_coffee_samples = pd.concat(dict_subsets, names=[\"coffee_bean_purchase_id\", \"sample_id\"]).reset_index()\n"
     ]
    }
   ],
   "source": [
    "dict_subsets = {}\n",
    "\n",
    "for purchase_id in df_purchase[\"id\"]:\n",
    "    variety_id = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"variety_id\"].values[0]\n",
    "    roast_lvl = df_variety.loc[df_variety[\"id\"] == variety_id, \"roast_level\"].values[0]\n",
    "    num_espresso = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"weight_kg\"].values[0] * 1000 // 20\n",
    "\n",
    "    df_sub = create_coffee_sample(\n",
    "        sample_size = num_espresso.astype(int),\n",
    "        selection_crit = roast_lvl,\n",
    "        random_state = 100 + purchase_id\n",
    "    )\n",
    "\n",
    "    purchase_date = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"purchase_date\"].values[0]\n",
    "    list_coffee_dt = []\n",
    "    random.seed(42 + purchase_id)\n",
    "    for i in df_sub.index:\n",
    "        rd_day = random.randint(1, 14)\n",
    "        rd_hour = random.randint(0, 9)\n",
    "        rd_minute = random.randint(0, 59)\n",
    "        coffee_dt = pd.to_datetime(purchase_date) + pd.to_timedelta(rd_day, unit=\"d\") + pd.to_timedelta(8 + rd_hour, unit=\"h\") + pd.to_timedelta(rd_minute, unit=\"m\")\n",
    "        list_coffee_dt.append(coffee_dt.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    df_sub[\"experiment_datetime\"] = list_coffee_dt\n",
    "\n",
    "    user_id = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"user_id\"].values[0]\n",
    "    users_defaults = df_defaults.loc[df_defaults[\"user_id\"] == user_id].drop(columns = [\"setup_name\"])\n",
    "    for col in users_defaults.columns:\n",
    "        df_sub[col] = users_defaults[col].values[0]\n",
    "\n",
    "    dict_subsets[purchase_id] = df_sub\n",
    "\n",
    "df_coffee_samples = pd.concat(dict_subsets, names=[\"coffee_bean_purchase_id\", \"sample_id\"]).reset_index()\n",
    "df_coffee_samples[\"id\"] = df_coffee_samples.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d07b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_cols(df, random_state = 42):\n",
    "    df[\"evaluation_general\"] = pd.Series(dtype = \"float\")\n",
    "    df[\"evaluation_flavor\"] = pd.Series(dtype = \"float\")\n",
    "    df[\"evaluation_body\"] = pd.Series(dtype = \"float\")\n",
    "    df[\"evaluation_crema\"] = pd.Series(dtype = \"float\")\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    def calculate_flavor(row):\n",
    "        if row[\"extr_ratio\"] <= 2:\n",
    "            val = ((-10)/2.25)*((row[\"extr_ratio\"] - 2)**2) + 10\n",
    "        else:\n",
    "            val = ((-10)/9)*((row[\"extr_ratio\"] - 2)**2) + 10\n",
    "        return val + np.random.normal(0, 0.5)\n",
    "    \n",
    "    def calculate_body(row):\n",
    "        if row[\"extr_ratio\"] <= 1.5:\n",
    "            val = (-10)*((row[\"extr_ratio\"] - 1.5)**2) + 10\n",
    "        else:\n",
    "            val = ((-10)/4)*((row[\"extr_ratio\"] - 1.5)**2) + 10\n",
    "        return val + np.random.normal(0, 0.5)\n",
    "    \n",
    "    def calculate_crema(row):\n",
    "        if row[\"extr_ratio\"] <= 2.2:\n",
    "            val = (-10)*((row[\"extr_ratio\"] - 2.2)**2) + 10\n",
    "        else:\n",
    "            val = ((-10)/4)*((row[\"extr_ratio\"] - 2.2)**2) + 10\n",
    "        return val + np.random.normal(0, 0.5)\n",
    "    \n",
    "    df[\"evaluation_flavor\"] = df.apply(calculate_flavor, axis=1)\n",
    "    df[\"evaluation_body\"] = df.apply(calculate_body, axis=1)\n",
    "    df[\"evaluation_crema\"] = df.apply(calculate_crema, axis=1)\n",
    "\n",
    "    def calculate_general(row):\n",
    "        flavor = row[\"evaluation_flavor\"]\n",
    "        body = row[\"evaluation_body\"]\n",
    "        crema = row[\"evaluation_crema\"]\n",
    "\n",
    "        return (flavor*3 + body*2 + crema) / 6 + np.random.normal(0, 0.5)\n",
    "    \n",
    "    df[\"evaluation_general\"] = df.apply(calculate_general, axis=1)\n",
    "\n",
    "    return df\n",
    "    \n",
    "def extra_flavor(df, random_state = 42):\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    def variety_effects(row):\n",
    "        purchase_id = row[\"coffee_bean_purchase_id\"]\n",
    "        coffee_id = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"variety_id\"].values[0]\n",
    "        origin_type = df_variety.loc[df_variety[\"id\"] == coffee_id, \"origin_type\"].values[0]\n",
    "        arabica_ratio = df_variety.loc[df_variety[\"id\"] == coffee_id, \"arabica_ratio\"].values[0]\n",
    "        intensity = df_variety.loc[df_variety[\"id\"] == coffee_id, \"intensity\"].values[0]\n",
    "        acidity = df_variety.loc[df_variety[\"id\"] == coffee_id, \"acidity\"].values[0]\n",
    "\n",
    "        extra_flavor = 0 - acidity \n",
    "        if origin_type == \"single origin\":\n",
    "            extra_flavor += 0.5\n",
    "        if arabica_ratio == 1.0:\n",
    "            extra_flavor += intensity \n",
    "\n",
    "        return row[\"evaluation_flavor\"] + extra_flavor + np.random.normal(0, 0.1)\n",
    "    \n",
    "    def machine_effects(row):\n",
    "        machine_id = row[\"coffee_machine_id\"]\n",
    "        portaf_diam = df_coffee_machines.loc[df_coffee_machines[\"id\"] == machine_id, \"portafilter_diam_mm\"].values[0]\n",
    "\n",
    "        grinder_id = row[\"grinder_id\"]\n",
    "        esp_range_min = df_grinders.loc[df_grinders[\"id\"] == grinder_id, \"min_espresso_range\"].values[0]\n",
    "        esp_range_max = df_grinders.loc[df_grinders[\"id\"] == grinder_id, \"max_espresso_range\"].values[0]\n",
    "        esp_range = esp_range_max - esp_range_min\n",
    "\n",
    "        extra_flavor = 0\n",
    "\n",
    "        if portaf_diam >= 58:\n",
    "            extra_flavor += 1\n",
    "        elif portaf_diam >= 54:\n",
    "            extra_flavor += 0.5\n",
    "        if esp_range >= 25:\n",
    "            extra_flavor += 0.5\n",
    "        elif esp_range >= 15:\n",
    "            extra_flavor += 0.25\n",
    "\n",
    "        return row[\"evaluation_flavor\"] + extra_flavor + np.random.normal(0, 0.1)\n",
    "\n",
    "    df[\"evaluation_flavor\"] = df.apply(variety_effects, axis=1)\n",
    "    df[\"evaluation_flavor\"] = df.apply(machine_effects, axis=1)\n",
    "    df[\"evaluation_general\"] = df[[\"evaluation_flavor\", \"evaluation_body\", \"evaluation_crema\"]].mean(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def scale_noise_int(df):\n",
    "    fl_min = df[\"evaluation_flavor\"].min()\n",
    "    fl_max = df[\"evaluation_flavor\"].max()\n",
    "    bd_min = df[\"evaluation_body\"].min()\n",
    "    bd_max = df[\"evaluation_body\"].max()\n",
    "    cr_min = df[\"evaluation_crema\"].min()\n",
    "    cr_max = df[\"evaluation_crema\"].max()\n",
    "    gen_min = df[\"evaluation_general\"].min()\n",
    "    gen_max = df[\"evaluation_general\"].max()\n",
    "\n",
    "    noise = {}\n",
    "    for i in range(4):\n",
    "        noise[i] = np.random.choice([-0.5, 0, 0.5], df.shape[0], p = [0.25, 0.5, 0.25])\n",
    "\n",
    "    df[\"evaluation_flavor\"] = ((df[\"evaluation_flavor\"] - fl_min) / (fl_max - fl_min)) * 10 + noise[0]\n",
    "    df[\"evaluation_body\"] = ((df[\"evaluation_body\"] - bd_min) / (bd_max - bd_min)) * 10 + noise[1]\n",
    "    df[\"evaluation_crema\"] = ((df[\"evaluation_crema\"] - cr_min) / (cr_max - cr_min)) * 10 + noise[2]\n",
    "    df[\"evaluation_general\"] = ((df[\"evaluation_general\"] - gen_min) / (gen_max - gen_min)) * 10 + noise[3]\n",
    "\n",
    "    df[\"evaluation_flavor\"] = df[\"evaluation_flavor\"].round(0).clip(1, 10).astype(int)\n",
    "    df[\"evaluation_body\"] = df[\"evaluation_body\"].round(0).clip(1, 10).astype(int)\n",
    "    df[\"evaluation_crema\"] = df[\"evaluation_crema\"].round(0).clip(1, 10).astype(int)\n",
    "    df[\"evaluation_general\"] = df[\"evaluation_general\"].round(0).clip(1, 10).astype(int)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c5ef6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_espresso_samples = create_eval_cols(df_coffee_samples.copy())\n",
    "df_espresso_samples = extra_flavor(df_espresso_samples.copy())\n",
    "df_espresso_samples = scale_noise_int(df_espresso_samples.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "002641c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_espresso_samples[\"water_temp_c\"] = 93\n",
    "df_espresso_samples[\"evaluation_notes\"] = \"\"\n",
    "\n",
    "df_espresso = df_espresso_samples[[\n",
    "    \"id\", \n",
    "    \"experiment_datetime\",\n",
    "    \"user_id\", \n",
    "    \"coffee_machine_id\", \n",
    "    \"grinder_id\", \n",
    "    \"basket_pressurized\",\n",
    "    \"basket_shot_size\",\n",
    "    \"portafilter_spout\",\n",
    "    \"wdt_used\",\n",
    "    \"tamping_method\",\n",
    "    \"tamping_weight_kg\",\n",
    "    \"leveler_used\",\n",
    "    \"puck_screen_used\",\n",
    "    \"puck_screen_thickness_mm\",\n",
    "    \"coffee_bean_purchase_id\",\n",
    "    \"grind_setting\",\n",
    "    \"dose_gr\",\n",
    "    \"water_temp_c\",\n",
    "    \"extraction_time_sec\",\n",
    "    \"yield_gr\",\n",
    "    \"evaluation_general\", \n",
    "    \"evaluation_flavor\",\n",
    "    \"evaluation_body\", \n",
    "    \"evaluation_crema\",\n",
    "    \"evaluation_notes\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf708be8",
   "metadata": {},
   "source": [
    "## Write dataframes to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7c445bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlmodel import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89e000fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "driver = os.getenv(\"DB_DRIVER\")\n",
    "connector = os.getenv(\"DB_CONNECTOR\")\n",
    "user = os.getenv(\"DB_USERNAME\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "port = os.getenv(\"DB_PORT\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "db_path = f\"{driver}+{connector}://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "db_engine = create_engine(db_path, echo = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.to_sql(\"Users\", db_engine, if_exists = \"append\", index = False)\n",
    "df_coffee_machines.to_sql(\"CoffeeMachines\", db_engine, if_exists = \"append\", index = False)\n",
    "df_grinders.to_sql(\"Grinders\", db_engine, if_exists = \"append\", index = False)\n",
    "df_equipment.to_sql(\"EquipmentOwnership\", db_engine, if_exists = \"append\", index = False)\n",
    "df_defaults.to_sql(\"UserDefaults\", db_engine, if_exists = \"append\", index = False)\n",
    "df_variety.to_sql(\"CoffeeBeanVarieties\", db_engine, if_exists = \"append\", index = False)\n",
    "df_purchase.to_sql(\"CoffeeBeanPurchases\", db_engine, if_exists = \"append\", index = False)\n",
    "df_espresso.to_sql(\"EspressoExperiments\", db_engine, if_exists = \"append\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espresso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
