{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea76594",
   "metadata": {},
   "source": [
    "# Generating mock data to populate the database\n",
    "\n",
    "This notebook creates one pandas dataframe for each table of the database, conforming to the schema as in init.sql script and db_models.py module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7dc7ee",
   "metadata": {},
   "source": [
    "Libraries for data processing and random data generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "768d861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from mimesis import Person, Address, Datetime, Text\n",
    "from mimesis.locales import Locale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d6f1e1",
   "metadata": {},
   "source": [
    "## Users\n",
    "\n",
    "For the Users table, create 12 users with real-looking information for Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1a9d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_users = {\n",
    "    \"id\" : [], \n",
    "    \"username\": [],\n",
    "    \"password_hash\": [],\n",
    "    \"email\": [],\n",
    "    \"first_name\": [],\n",
    "    \"last_name\": [],\n",
    "    \"date_of_birth\": [],\n",
    "    \"street_address\": [],\n",
    "    \"city\": [],\n",
    "    \"postal_code\": [],\n",
    "    \"registration_datetime\": [],\n",
    "    \"user_type\": [],\n",
    "}\n",
    "\n",
    "N_USERS = 12\n",
    "\n",
    "for id in range(1, N_USERS + 1):\n",
    "    person_gen = Person(Locale.DE, seed = 42 + id)\n",
    "    address_gen = Address(Locale.DE, seed = 42 + id)\n",
    "    date_gen = Datetime(Locale.DE, seed = 42 + id)\n",
    "\n",
    "    dict_users[\"id\"].append(id)\n",
    "    dict_users[\"username\"].append(person_gen.username())\n",
    "    dict_users[\"password_hash\"].append(person_gen.password(hashed = True))\n",
    "    dict_users[\"email\"].append(person_gen.email())\n",
    "    dict_users[\"first_name\"].append(person_gen.first_name())\n",
    "    dict_users[\"last_name\"].append(person_gen.last_name())\n",
    "    dict_users[\"date_of_birth\"].append(person_gen.birthdate(min_year = 1960, max_year = 2000).strftime(\"%Y-%m-%d\"))\n",
    "    dict_users[\"street_address\"].append(address_gen.address())\n",
    "    dict_users[\"city\"].append(address_gen.city())\n",
    "    dict_users[\"postal_code\"].append(address_gen.postal_code())\n",
    "    dict_users[\"registration_datetime\"].append(date_gen.datetime(start = 2023, end = 2024).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    dict_users[\"user_type\"].append(\"test\")\n",
    "\n",
    "df_users = pd.DataFrame(dict_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8412c",
   "metadata": {},
   "source": [
    "## Coffee machines\n",
    "\n",
    "For the CoffeeMachines table, enter values manually for 6 machines (info not necessarily accurate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6098c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coffee_machines = pd.DataFrame(\n",
    "    columns = [\n",
    "        \"id\", \n",
    "        \"manufacturer\",\n",
    "        \"model_name\",\n",
    "        \"model_name_add\",\n",
    "        \"model_specification\",\n",
    "        \"product_identifier\",\n",
    "        \"pump_pressure_bar\",\n",
    "        \"pump_type\",\n",
    "        \"water_temp_control\",\n",
    "        \"pid_control\",\n",
    "        \"boiler_type\",\n",
    "        \"portafilter_diam_mm\"\n",
    "    ], \n",
    "    data = [\n",
    "        (1, 'DeLonghi', 'Dedica', '', 'Black', 'EC685.BK', 15, 'vibrating', 'no', '', 'single boiler', 51),\n",
    "        (2, 'Sage/Breville', 'Barista', 'Pro', 'Brushed Stainless Steel', 'SES878BSS4EEU1', 15, 'vibrating', 'yes', 'automatic', 'dual boiler', 54),\n",
    "        (3, 'Sage/Breville', 'Oracle', 'Touch', 'Matte Black', 'SES990BSS4EEU1', 9, 'vibrating', 'yes', 'programmable', 'dual boiler', 58),\n",
    "        (4, 'Lelit', 'Bianca', '', 'Steel', 'LE-PL162T V3', 10, 'rotary pump', 'yes', 'programmable', 'dual boiler ', 58),\n",
    "        (5, 'DeLonghi', 'La Specialista', 'Arte', 'Yellow', 'EC9155.YE', 15, 'vibrating', 'no', '', 'single boiler', 51),\n",
    "        (6, 'Sage/Breville', 'Barista', 'Express', 'Black truffle', 'SES875BTR2EEU1', 9, 'vibrating', 'yes', 'automatic', 'dual boiler', 54),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e7998",
   "metadata": {},
   "source": [
    "## Grinders\n",
    "\n",
    "For the Grinders table, enter values manually for 5 grinders (info not necessarily accurate, and some fields left empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4bf9e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grinders = pd.DataFrame(\n",
    "    columns = [\n",
    "        \"id\",\n",
    "        \"manufacturer\",\n",
    "        \"model_name\",\n",
    "        \"model_name_add\",\n",
    "        \"model_specification\",\n",
    "        \"product_identifier\",\n",
    "        \"operation_type\",\n",
    "        \"burr_shape\",\n",
    "        \"burr_diameter_mm\",\n",
    "        \"burr_material\",\n",
    "        \"min_setting\",\n",
    "        \"max_setting\",\n",
    "        \"min_espresso_range\",\n",
    "        \"max_espresso_range\",\n",
    "        \"single_dose\"\n",
    "    ],\n",
    "    data = [\n",
    "        (1, 'Baratza', 'Encore', 'ESP', 'Black', '495W-230V-F', 'electric', '', pd.NA, '', 0, 40, 0, 20, 'no'), \n",
    "        (2, 'Sage/Breville', 'The Smart Grinder', 'Pro', 'Brushed Stainless Steel', 'SCG820BSS4EEU1', 'electric', '', pd.NA, '', 1, 60, 1, 30, 'no'), \n",
    "        (3, 'Eureka', 'Mignon', 'Oro', 'Black', 'EAN 8059519339448', 'electric', '', pd.NA, '', 0, 30, 0, 8, 'no'), \n",
    "        (4, 'Hario', 'Skerton', 'Plus', 'Schwarz', 'B01LXZACFB', 'manual', '', pd.NA, '', pd.NA, pd.NA, pd.NA, pd.NA, 'no'), \n",
    "        (5, 'DeLonghi', 'Dedica', 'Grinder', 'Steel, Silver ', 'KG520.M', 'electric', '', pd.NA, '', 1, 18, pd.NA, pd.NA, 'no')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03af70",
   "metadata": {},
   "source": [
    "## Equipment ownership\n",
    "\n",
    "Assign coffee machines and grinders to different users, which will be stored in EquipmentOwnership table. Match 6 coffee machines and 3 grinders in different combinations (`np.repeat` for machines and `np.tile` for grinders). Add some random purchasing info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "439bcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_equipment = {\n",
    "    \"id\": [],\n",
    "    \"user_id\": [],\n",
    "    \"equipment_type\": [],\n",
    "    \"coffee_machine_id\": [],\n",
    "    \"grinder_id\": [],\n",
    "    \"purchase_date\": [],\n",
    "    \"purchased_from\": [], \n",
    "    \"purchase_price_eur\": []\n",
    "}\n",
    "\n",
    "N_COFFEE_MACHINES = 6\n",
    "N_GRINDERS = 3\n",
    "\n",
    "dict_equipment[\"id\"] = np.arange(1, N_USERS*2 + 1).tolist()\n",
    "dict_equipment[\"user_id\"] = np.tile(range(1, N_USERS + 1), 2).tolist()\n",
    "dict_equipment[\"equipment_type\"] = np.repeat([\"coffee_machine\", \"grinder\"], N_USERS).tolist()\n",
    "dict_equipment[\"coffee_machine_id\"] = np.concatenate((\n",
    "    np.repeat(range(1, N_COFFEE_MACHINES + 1), N_USERS // N_COFFEE_MACHINES),\n",
    "    np.repeat(np.nan, N_USERS)\n",
    ")).tolist()\n",
    "dict_equipment[\"grinder_id\"] = np.concatenate((\n",
    "    np.repeat(np.nan, N_USERS), \n",
    "    np.tile(range(1, N_GRINDERS + 1), N_USERS // N_GRINDERS)\n",
    ")).tolist()\n",
    "\n",
    "for i in range(1, N_USERS*2 + 1):\n",
    "    date_gen = Datetime(Locale.DE, seed = 42 + i)\n",
    "    random.seed(42 + i)\n",
    "    dict_equipment[\"purchase_date\"].append(date_gen.date(start = 2018, end = 2024).strftime(\"%Y-%m-%d\"))\n",
    "    dict_equipment[\"purchased_from\"].append(random.choice([\"Amazon\", \"eBay\", \"Mediamarkt\", \"Roastmarket\", \"Local Store\"]))\n",
    "    dict_equipment[\"purchase_price_eur\"].append(np.nan)\n",
    "\n",
    "df_equipment = pd.DataFrame(dict_equipment)\n",
    "df_equipment[\"coffee_machine_id\"] = df_equipment[\"coffee_machine_id\"].astype(pd.Int64Dtype())\n",
    "df_equipment[\"grinder_id\"] = df_equipment[\"grinder_id\"].astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25870bfc",
   "metadata": {},
   "source": [
    "## User defaults\n",
    "\n",
    "For each user, define a default setup for equipments and preparation details, which will be stored in the UserDefaults table. Coffee machine and grinder align with ownership. Some info constant (basket not pressurized, tamping manual, etc.), some random (wdt, leveler, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "caab9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_defaults = {\n",
    "    \"user_id\" : [], \n",
    "    \"coffee_machine_id\": [],\n",
    "    \"grinder_id\": [],\n",
    "    \"basket_pressurized\": [],\n",
    "    \"basket_shot_size\": [],\n",
    "    \"portafilter_spout\": [],\n",
    "    \"wdt_used\": [],\n",
    "    \"tamping_method\": [],\n",
    "    \"tamping_weight_kg\": [],\n",
    "    \"leveler_used\": [],\n",
    "    \"puck_screen_used\": [],\n",
    "    \"puck_screen_thickness_mm\": [],\n",
    "    \"setup_name\": []\n",
    "}\n",
    "\n",
    "dict_defaults[\"user_id\"] = np.arange(1, N_USERS + 1).tolist()\n",
    "dict_defaults[\"coffee_machine_id\"] = np.repeat(range(1, N_COFFEE_MACHINES + 1), N_USERS // N_COFFEE_MACHINES).tolist()\n",
    "dict_defaults[\"grinder_id\"] = np.tile(range(1, N_GRINDERS + 1), N_USERS // N_GRINDERS).tolist()\n",
    "dict_defaults[\"basket_pressurized\"] = [\"no\" for _ in range(N_USERS)]\n",
    "dict_defaults[\"basket_shot_size\"] = [\"double\" for _ in range(N_USERS)]\n",
    "dict_defaults[\"portafilter_spout\"] = [\"double\" for _ in range(N_USERS)]\n",
    "np.random.seed(42)\n",
    "dict_defaults[\"wdt_used\"] = np.random.choice([\"yes\", \"no\"], N_USERS, p=[0.5, 0.5]).tolist()\n",
    "dict_defaults[\"tamping_method\"] = [\"manual\" for _ in range(N_USERS)]\n",
    "dict_defaults[\"tamping_weight_kg\"] = [pd.NA for _ in range(N_USERS)]\n",
    "dict_defaults[\"leveler_used\"] = np.random.choice([\"yes\", \"no\"], N_USERS, p=[0.3, 0.7]).tolist()\n",
    "dict_defaults[\"puck_screen_used\"] = np.random.choice([\"yes\", \"no\"], N_USERS, p=[0.5, 0.5]).tolist()\n",
    "dict_defaults[\"puck_screen_thickness_mm\"] = [pd.NA for _ in range(N_USERS)]\n",
    "for i in dict_defaults[\"user_id\"]:\n",
    "    users_name = df_users.loc[df_users[\"id\"] == i, \"first_name\"].values[0]\n",
    "    dict_defaults[\"setup_name\"].append(f\"{users_name}'s Setup\")\n",
    "\n",
    "df_defaults = pd.DataFrame(dict_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26887f4",
   "metadata": {},
   "source": [
    "Normally, additional portafilters are needed for DeLonghi machines to make them non-pressurized; these are defined as bottomless for some variation. Furthermoe, puck screen thickness is given random values if used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fac39ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_defaults.loc[df_defaults[\"coffee_machine_id\"].isin([1, 6]), \"portafilter_spout\"] = \"bottomless\"\n",
    "n_puck_screens = df_defaults[\"puck_screen_used\"].value_counts().get(\"yes\", 0)\n",
    "df_defaults.loc[df_defaults[\"puck_screen_used\"] == \"yes\", \"puck_screen_thickness_mm\"] = np.random.choice([1.0, 1.7, 2.0], n_puck_screens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dde98f",
   "metadata": {},
   "source": [
    "## Coffee varieties\n",
    "\n",
    "This section will generate data for the table CoffeeBeanVarieties. Different logics will be applied for single-origin and blend varieties regarding arabica content, then these subsets will be combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b53413",
   "metadata": {},
   "source": [
    "### Single origin - arabica\n",
    "\n",
    "For single origin, intensity will be relatively lower, and never 10/10; acidity always low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ec81bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roast_rating_10 = np.array([6, 8, 10])\n",
    "roast_relative = roast_rating_10 / 10\n",
    "\n",
    "intensity_rating_10 = np.array([5, 7, 9])\n",
    "intensity_relative = intensity_rating_10 / 10\n",
    "\n",
    "acidity_rating_10 = np.array([2])\n",
    "acidity_relative = acidity_rating_10 / 10\n",
    "\n",
    "grid = np.array(np.meshgrid(\n",
    "    roast_relative,\n",
    "    intensity_relative,\n",
    "    acidity_relative,\n",
    ")).T.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7666014e",
   "metadata": {},
   "source": [
    "Here single origin will also mean 100% Arabica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "987d3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variety_so = pd.DataFrame(grid, \n",
    "    columns=[\n",
    "        'roast_level', \n",
    "        'intensity', \n",
    "        'acidity']\n",
    ")\n",
    "\n",
    "df_variety_so[\"origin_type\"] = \"single origin\"\n",
    "df_variety_so[\"arabica_ratio\"] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c9b45",
   "metadata": {},
   "source": [
    "Add some random origins, and nonsensical two-word names as if from some Latin American countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce966466",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_variety_so)):\n",
    "    random.seed(42 + i)\n",
    "    origin_name = random.choice([\"Colombia\", \"Brazil\", \"Honduras\", \"Peru\", \"Mexico\", \"Gueatemala\"])\n",
    "    df_variety_so.at[i, \"origin\"] = origin_name\n",
    "\n",
    "    if origin_name == \"Brazil\":\n",
    "        locale = Locale.PT_BR\n",
    "    else:\n",
    "        locale = Locale.ES_MX\n",
    "    \n",
    "    text_gen = Text(locale, seed=42 + i)\n",
    "    df_variety_so.at[i, \"name\"] = f\"{text_gen.color()} {text_gen.word()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c526a2",
   "metadata": {},
   "source": [
    "### Blend - arabica-robusta\n",
    "\n",
    "For blend varieties, intensity is higher and relatively higher acidity is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "477e9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "roast_rating_10 = np.array([6, 8, 10])\n",
    "roast_relative = roast_rating_10 / 10\n",
    "\n",
    "intensity_rating_10 = np.array([8, 10])\n",
    "intensity_relative = intensity_rating_10 / 10\n",
    "\n",
    "acidity_rating_10 = np.array([2, 4])\n",
    "acidity_relative = acidity_rating_10 / 10\n",
    "\n",
    "grid = np.array(np.meshgrid(\n",
    "    roast_relative,\n",
    "    intensity_relative,\n",
    "    acidity_relative,\n",
    ")).T.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43df5f2f",
   "metadata": {},
   "source": [
    "Assume there are no 100% Arabica blends for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9cfc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variety_blend = pd.DataFrame(grid,\n",
    "    columns=[\n",
    "        'roast_level', \n",
    "        'intensity', \n",
    "        'acidity']\n",
    ")\n",
    "\n",
    "df_variety_blend[\"origin_type\"] = \"blend\"\n",
    "df_variety_blend[\"arabica_ratio\"] = np.random.choice([0.7, 0.8], len(df_variety_blend), p=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fa840",
   "metadata": {},
   "source": [
    "Add some random origins, and nonsensical two-word names some of them as if from Latin America, and some named like Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6aa1527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_variety_blend)):\n",
    "    random.seed(2025 + i)\n",
    "    origin_name = random.choice([\"Latin America\", \"Unspecified\"])\n",
    "    df_variety_blend.at[i, \"origin\"] = origin_name\n",
    "\n",
    "    if origin_name == \"Latin America\":\n",
    "        locale = Locale.ES_MX\n",
    "    else:\n",
    "        locale = Locale.IT\n",
    "    \n",
    "    text_gen = Text(locale, seed = 2025 + i)\n",
    "    df_variety_blend.at[i, \"name\"] = f\"{text_gen.color()} {text_gen.word()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc021c10",
   "metadata": {},
   "source": [
    "### Blend - arabica\n",
    "\n",
    "Relatively dark roast, but not too intense, and low acidity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23db3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "roast_rating_10 = np.array([8, 10])\n",
    "roast_relative = roast_rating_10 / 10\n",
    "\n",
    "intensity_rating_10 = np.array([6, 8])\n",
    "intensity_relative = intensity_rating_10 / 10\n",
    "\n",
    "acidity_rating_10 = np.array([2])\n",
    "acidity_relative = acidity_rating_10 / 10\n",
    "\n",
    "grid = np.array(np.meshgrid(\n",
    "    roast_relative,\n",
    "    intensity_relative,\n",
    "    acidity_relative,\n",
    ")).T.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f9bcda",
   "metadata": {},
   "source": [
    "These will be 100% Arabica but from different origins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42a2dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variety_arbl = pd.DataFrame(grid,\n",
    "    columns=[\n",
    "        'roast_level', \n",
    "        'intensity', \n",
    "        'acidity']\n",
    ")\n",
    "\n",
    "df_variety_arbl[\"origin_type\"] = \"blend\"\n",
    "df_variety_arbl[\"arabica_ratio\"] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e4ed1",
   "metadata": {},
   "source": [
    "Same naming as mixed blends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80714aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_variety_arbl)):\n",
    "    random.seed(101 + i)\n",
    "    origin_name = random.choice([\"Latin America\", \"Unspecified\"])\n",
    "    df_variety_arbl.at[i, \"origin\"] = origin_name\n",
    "\n",
    "    if origin_name == \"Latin America\":\n",
    "        locale = Locale.ES_MX\n",
    "    else:\n",
    "        locale = Locale.IT\n",
    "    \n",
    "    text_gen = Text(locale, seed = 101 + i)\n",
    "    df_variety_arbl.at[i, \"name\"] = f\"{text_gen.color()} {text_gen.word()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4948e82",
   "metadata": {},
   "source": [
    "### Combined\n",
    "\n",
    "Combine these three, and add some random made-up roasting house names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "971fe5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variety = pd.concat([df_variety_so, df_variety_blend, df_variety_arbl], ignore_index=True)\n",
    "\n",
    "df_variety[\"decaffeinated\"] = \"no\"\n",
    "\n",
    "producer_list = [\n",
    "    \"Bean Masters\", \n",
    "    \"Coffee Artisans\", \n",
    "    \"Brewed Perfection\", \n",
    "    \"Roast Revolution\", \n",
    "    \"Espresso Excellence\"\n",
    "]\n",
    "\n",
    "df_variety[\"producer\"] = np.random.choice(producer_list, len(df_variety))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706ff94",
   "metadata": {},
   "source": [
    "Add some random flavor notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62aaf486",
   "metadata": {},
   "outputs": [],
   "source": [
    "flavor_list = [\n",
    "    \"chocolate\", \n",
    "    \"dark chocolate\",\n",
    "    \"caramel\", \n",
    "    \"citrus\", \n",
    "    \"berry\", \n",
    "    \"fruity\",\n",
    "    \"nutty\", \n",
    "    \"hazelnut\",\n",
    "    \"vanilla\",\n",
    "    \"floral\", \n",
    "    \"spicy\", \n",
    "    \"smoky\"\n",
    "]\n",
    "\n",
    "for i in range(len(df_variety)):\n",
    "    random.seed(42 + i)\n",
    "    n_flavors = random.randint(1, 3)\n",
    "    flavors = random.sample(flavor_list, n_flavors)\n",
    "    df_variety.at[i, \"flavor_notes\"] = \", \".join(flavors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e6d18",
   "metadata": {},
   "source": [
    "Shape the final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00a0440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variety = df_variety.reset_index(drop = True)\n",
    "df_variety = df_variety.reset_index(names = \"id\")\n",
    "df_variety[\"id\"] = df_variety[\"id\"] + 1\n",
    "\n",
    "df_variety = df_variety[[\n",
    "    \"id\", \n",
    "    \"producer\", \n",
    "    \"name\",\n",
    "    \"origin\",\n",
    "    \"origin_type\",\n",
    "    \"arabica_ratio\",\n",
    "    \"roast_level\",\n",
    "    \"intensity\",\n",
    "    \"acidity\",\n",
    "    \"flavor_notes\", \n",
    "    \"decaffeinated\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a2cde",
   "metadata": {},
   "source": [
    "## Coffee purchases\n",
    "\n",
    "Go through all varieties, assign to a user as purchase, and this will be stored in the table CoffeeBeanPurchases. Add some random data about purchase details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3f45d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_purchase = {\n",
    "    \"user_id\": [],\n",
    "    \"variety_id\": [],\n",
    "    \"purchase_date\": [],\n",
    "    \"purchased_from\": [],\n",
    "    \"weight_kg\": [],\n",
    "    \"price_per_kg_eur\": []\n",
    "}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(len(df_variety) * 4):\n",
    "    date_gen = Datetime(Locale.DE, seed = 42 + i)\n",
    "\n",
    "    user_id = (i % N_USERS) + 1\n",
    "    variety_id = (i % len(df_variety)) + 1\n",
    "    purchase_date = date_gen.date(start = 2025).strftime(\"%Y-%m-%d\")\n",
    "    purchased_from = random.choice([\"Amazon\", \"Roastmarket\", \"Edeka\", \"Rewe\", \"Local roaster\"])\n",
    "    weight_kg = np.random.choice([0.25, 0.5, 1, 1.5], p = [0.3, 0.2, 0.4, 0.1])\n",
    "    price_per_kg_eur = round(np.random.normal(25, 2), 2)\n",
    "\n",
    "    dict_purchase[\"user_id\"].append(user_id)\n",
    "    dict_purchase[\"variety_id\"].append(variety_id)\n",
    "    dict_purchase[\"purchase_date\"].append(purchase_date)\n",
    "    dict_purchase[\"purchased_from\"].append(purchased_from)\n",
    "    dict_purchase[\"weight_kg\"].append(weight_kg)\n",
    "    dict_purchase[\"price_per_kg_eur\"].append(price_per_kg_eur)\n",
    "\n",
    "df_purchase = pd.DataFrame(dict_purchase)\n",
    "df_purchase = df_purchase.reset_index(names = \"id\")\n",
    "df_purchase[\"id\"] = df_purchase[\"id\"] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a00ec",
   "metadata": {},
   "source": [
    "## Espresso\n",
    "\n",
    "To generate data for the table EspressoExperiments, some made-up relationships are defined here between coffee variety features, extraction parameters, preparation details, and coffee evaluation.\n",
    "\n",
    "In the first place, extraction ratio is calculated as a function of roast level, grind level, dose, and extraction duration. Below the input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fcebcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roast_rating_10 = np.array([6, 8, 10])\n",
    "roast_relative = roast_rating_10 / 10\n",
    "\n",
    "grind_settings_20 = np.array([5, 6, 8, 10, 12, 15, 18])\n",
    "grind_relative = grind_settings_20 / 20\n",
    "\n",
    "dose_gr = np.array([16, 17, 17.5, 18, 18.5, 19, 20])\n",
    "dose_relative = (dose_gr - 15) / 5\n",
    "\n",
    "extr_sec = np.array([20, 23, 25, 27, 30])\n",
    "extr_relative = (extr_sec - 20) / 20 + 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2db4f3",
   "metadata": {},
   "source": [
    "Extraction ratio is positively related to the grind size and extraction duration, and negatively with roast level and dose. With arbitrary coefficients and operations, extraction ratio data are generated in a range of 0.75 to 3.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1a083839",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.array(np.meshgrid(roast_relative, grind_relative, dose_relative, extr_relative)).T.reshape(-1, 4)\n",
    "extr_ratio_raw = 2*grid[:, 1] - grid[:, 0] - grid[:, 2]\n",
    "extr_ratio_scaled = ((extr_ratio_raw - np.min(extr_ratio_raw)) / (np.max(extr_ratio_raw) - np.min(extr_ratio_raw))) * 2 + 1\n",
    "extr_ratio_time_adj = extr_ratio_scaled * grid[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b22b27",
   "metadata": {},
   "source": [
    "Turn the resulting numpy array to pandas dataframe for further operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0a61d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_nparray = np.array(np.meshgrid(roast_relative, grind_relative, dose_gr, extr_sec)).T.reshape(-1, 4)\n",
    "baseline_nparray = np.column_stack((baseline_nparray, extr_ratio_time_adj))\n",
    "df_baseline = pd.DataFrame(baseline_nparray, columns=['roast', 'grind', 'dose', 'extr_sec', 'extr_ratio'])\n",
    "for col in df_baseline:\n",
    "    df_baseline[col] = df_baseline[col].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff8e35",
   "metadata": {},
   "source": [
    "Assuming users will try to get an extraction ratio between 1.5 and 2.0, we should get more values in and around this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4046a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_from_extr_ratio(extr_ratio):\n",
    "    if extr_ratio >= 1.5 and extr_ratio <= 2:\n",
    "        return 3\n",
    "    elif extr_ratio < 1.5 and extr_ratio >= 1:\n",
    "        return 2\n",
    "    elif extr_ratio > 2 and extr_ratio <= 2.75:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df_baseline[\"sampling_weight\"] = df_baseline[\"extr_ratio\"].apply(get_weight_from_extr_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28fe540",
   "metadata": {},
   "source": [
    "The below function takes a sample (with replacement) of espressos from the above dataframe according to a selection criteria (e.g. roast level 0.8). It also adds some random variation to extraction ratio and yield. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc120f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coffee_sample(\n",
    "        baseline = df_baseline,\n",
    "        selection_col = \"roast\", \n",
    "        selection_crit = 0.8,\n",
    "        sample_size = 50, \n",
    "        weight_col = \"sampling_weight\",\n",
    "        random_state = 42,\n",
    "        extr_ratio_col = \"extr_ratio\",\n",
    "        extr_ratio_shift = 0, \n",
    "        extr_ratio_sd = 0.1,\n",
    "        dose_col = \"dose\",\n",
    "        yield_shift = 0,\n",
    "        yield_sd = 1,\n",
    "):\n",
    "    new_df = baseline[baseline[selection_col] == selection_crit].sample(\n",
    "        n = sample_size,\n",
    "        replace = True,\n",
    "        weights = weight_col,\n",
    "        random_state = random_state\n",
    "    )\n",
    "    new_df = new_df.drop(columns=[weight_col])\n",
    "    new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    new_df[extr_ratio_col] = new_df[extr_ratio_col] + np.random.normal(\n",
    "        loc = extr_ratio_shift,\n",
    "        scale = extr_ratio_sd,\n",
    "        size = new_df.shape[0]\n",
    "    )\n",
    "\n",
    "    new_df[\"yield_gr\"] = new_df[dose_col] * new_df[extr_ratio_col]\n",
    "    new_df[\"yield_gr\"] = new_df[\"yield_gr\"] + np.random.normal(\n",
    "        loc = yield_shift,\n",
    "        scale = yield_sd,\n",
    "        size = new_df.shape[0]\n",
    "    )\n",
    "    new_df[\"yield_gr\"] = new_df[\"yield_gr\"].round(1)\n",
    "\n",
    "    new_df = new_df.rename(columns={\n",
    "        \"grind\": \"grind_setting\",\n",
    "        \"dose\": \"dose_gr\",\n",
    "        \"extr_sec\": \"extraction_time_sec\"\n",
    "    })\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296bb7d",
   "metadata": {},
   "source": [
    "Using that function, the below procedure creates a sample of espressos for each coffee purchase corresponding to its roast level. The sample size (number of espressos) depends on the amount of coffee purchased (randomly assigned in the generation of purchase data). The experiment datetime is randomly generated, but fallss within a fortnight of the purchase and is during daytime. The default equipment and preparation setup of the user who purchased the coffee is integrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b7bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14058/3956816567.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_coffee_samples = pd.concat(dict_subsets, names=[\"coffee_bean_purchase_id\", \"sample_id\"]).reset_index()\n"
     ]
    }
   ],
   "source": [
    "dict_subsets = {}\n",
    "\n",
    "for purchase_id in df_purchase[\"id\"]:\n",
    "    variety_id = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"variety_id\"].values[0]\n",
    "    roast_lvl = df_variety.loc[df_variety[\"id\"] == variety_id, \"roast_level\"].values[0]\n",
    "    num_espresso = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"weight_kg\"].values[0] * 1000 // 20\n",
    "\n",
    "    df_sub = create_coffee_sample(\n",
    "        sample_size = num_espresso.astype(int),\n",
    "        selection_crit = roast_lvl,\n",
    "        random_state = 100 + purchase_id\n",
    "    )\n",
    "\n",
    "    purchase_date = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"purchase_date\"].values[0]\n",
    "    list_coffee_dt = []\n",
    "    random.seed(42 + purchase_id)\n",
    "    for i in df_sub.index:\n",
    "        rd_day = random.randint(1, 14)\n",
    "        rd_hour = random.randint(0, 9)\n",
    "        rd_minute = random.randint(0, 59)\n",
    "        coffee_dt = pd.to_datetime(purchase_date) + pd.to_timedelta(rd_day, unit=\"d\") + pd.to_timedelta(8 + rd_hour, unit=\"h\") + pd.to_timedelta(rd_minute, unit=\"m\")\n",
    "        list_coffee_dt.append(coffee_dt.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    df_sub[\"experiment_datetime\"] = list_coffee_dt\n",
    "\n",
    "    user_id = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"user_id\"].values[0]\n",
    "    users_defaults = df_defaults.loc[df_defaults[\"user_id\"] == user_id].drop(columns = [\"setup_name\"])\n",
    "    for col in users_defaults.columns:\n",
    "        df_sub[col] = users_defaults[col].values[0]\n",
    "\n",
    "    dict_subsets[purchase_id] = df_sub\n",
    "\n",
    "df_coffee_samples = pd.concat(dict_subsets, names=[\"coffee_bean_purchase_id\", \"sample_id\"]).reset_index()\n",
    "df_coffee_samples[\"id\"] = df_coffee_samples.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceea957",
   "metadata": {},
   "source": [
    "The functions below create coffee evaluation columns. To calculate values between 1 and 10, they assume a primary relationship between extraction ratio and evaluation, in the form of a convex-down parabola, with the vertex at the coordinates of a moderate extraction ratio and 10. Assuming that more diluted coffees are more tolerable than extremely dense coffees, two parabolae are used for each calculation, meeting at the vertex, and left-hand side being more steep. \n",
    "\n",
    "Evaluation of flavor, body, and crema are calculated with slightly varying parameters, and a general evaluation is calculated as a weighted average, giving more weight to flavor, then body. At each stage, some random variation is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d07b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_cols(df, random_state = 42):\n",
    "    df[\"evaluation_general\"] = pd.Series(dtype = \"float\")\n",
    "    df[\"evaluation_flavor\"] = pd.Series(dtype = \"float\")\n",
    "    df[\"evaluation_body\"] = pd.Series(dtype = \"float\")\n",
    "    df[\"evaluation_crema\"] = pd.Series(dtype = \"float\")\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    def calculate_flavor(row):\n",
    "        if row[\"extr_ratio\"] <= 2:\n",
    "            val = ((-10)/2.25)*((row[\"extr_ratio\"] - 2)**2) + 10\n",
    "        else:\n",
    "            val = ((-10)/9)*((row[\"extr_ratio\"] - 2)**2) + 10\n",
    "        return val + np.random.normal(0, 0.5)\n",
    "    \n",
    "    def calculate_body(row):\n",
    "        if row[\"extr_ratio\"] <= 1.5:\n",
    "            val = (-10)*((row[\"extr_ratio\"] - 1.5)**2) + 10\n",
    "        else:\n",
    "            val = ((-10)/4)*((row[\"extr_ratio\"] - 1.5)**2) + 10\n",
    "        return val + np.random.normal(0, 0.5)\n",
    "    \n",
    "    def calculate_crema(row):\n",
    "        if row[\"extr_ratio\"] <= 2.2:\n",
    "            val = (-10)*((row[\"extr_ratio\"] - 2.2)**2) + 10\n",
    "        else:\n",
    "            val = ((-10)/4)*((row[\"extr_ratio\"] - 2.2)**2) + 10\n",
    "        return val + np.random.normal(0, 0.5)\n",
    "    \n",
    "    df[\"evaluation_flavor\"] = df.apply(calculate_flavor, axis=1)\n",
    "    df[\"evaluation_body\"] = df.apply(calculate_body, axis=1)\n",
    "    df[\"evaluation_crema\"] = df.apply(calculate_crema, axis=1)\n",
    "\n",
    "    def calculate_general(row):\n",
    "        flavor = row[\"evaluation_flavor\"]\n",
    "        body = row[\"evaluation_body\"]\n",
    "        crema = row[\"evaluation_crema\"]\n",
    "\n",
    "        return (flavor*3 + body*2 + crema) / 6 + np.random.normal(0, 0.5)\n",
    "    \n",
    "    df[\"evaluation_general\"] = df.apply(calculate_general, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7675e44",
   "metadata": {},
   "source": [
    "The below function takes into account some extra factors that might influence flavor. First, for coffee varieties, acidity is considered as negative, single origin as positive, and intensity as positive insofar as it only consists of arabica beans. Second, for coffee machines and grinders, the portafilter diameters size and fine (espresso) grinding range are taken as potentially positive contributions, again with some additional random variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2dee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_flavor(df, random_state = 42):\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    def variety_effects(row):\n",
    "        purchase_id = row[\"coffee_bean_purchase_id\"]\n",
    "        coffee_id = df_purchase.loc[df_purchase[\"id\"] == purchase_id, \"variety_id\"].values[0]\n",
    "        origin_type = df_variety.loc[df_variety[\"id\"] == coffee_id, \"origin_type\"].values[0]\n",
    "        arabica_ratio = df_variety.loc[df_variety[\"id\"] == coffee_id, \"arabica_ratio\"].values[0]\n",
    "        intensity = df_variety.loc[df_variety[\"id\"] == coffee_id, \"intensity\"].values[0]\n",
    "        acidity = df_variety.loc[df_variety[\"id\"] == coffee_id, \"acidity\"].values[0]\n",
    "\n",
    "        extra_flavor = 0 - acidity \n",
    "        if origin_type == \"single origin\":\n",
    "            extra_flavor += 0.5\n",
    "        if arabica_ratio == 1.0:\n",
    "            extra_flavor += intensity \n",
    "\n",
    "        return row[\"evaluation_flavor\"] + extra_flavor + np.random.normal(0, 0.1)\n",
    "    \n",
    "    def machine_effects(row):\n",
    "        machine_id = row[\"coffee_machine_id\"]\n",
    "        portaf_diam = df_coffee_machines.loc[df_coffee_machines[\"id\"] == machine_id, \"portafilter_diam_mm\"].values[0]\n",
    "\n",
    "        grinder_id = row[\"grinder_id\"]\n",
    "        esp_range_min = df_grinders.loc[df_grinders[\"id\"] == grinder_id, \"min_espresso_range\"].values[0]\n",
    "        esp_range_max = df_grinders.loc[df_grinders[\"id\"] == grinder_id, \"max_espresso_range\"].values[0]\n",
    "        esp_range = esp_range_max - esp_range_min\n",
    "\n",
    "        extra_flavor = 0\n",
    "\n",
    "        if portaf_diam >= 58:\n",
    "            extra_flavor += 1\n",
    "        elif portaf_diam >= 54:\n",
    "            extra_flavor += 0.5\n",
    "        if esp_range >= 25:\n",
    "            extra_flavor += 0.5\n",
    "        elif esp_range >= 15:\n",
    "            extra_flavor += 0.25\n",
    "\n",
    "        return row[\"evaluation_flavor\"] + extra_flavor + np.random.normal(0, 0.1)\n",
    "\n",
    "    df[\"evaluation_flavor\"] = df.apply(variety_effects, axis=1)\n",
    "    df[\"evaluation_flavor\"] = df.apply(machine_effects, axis=1)\n",
    "    df[\"evaluation_general\"] = df[[\"evaluation_flavor\", \"evaluation_body\", \"evaluation_crema\"]].mean(axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c0c95d",
   "metadata": {},
   "source": [
    "The next function scales the values to a range of 1 to 10, and rounds up to the closest integer. Before rounding up, increases or decreases half of the values by 0.5, to mix up adjacent categories, hence to add some more noise to the data (evaluation is supposed to be quite subjective and volatile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_noise_int(df):\n",
    "    fl_min = df[\"evaluation_flavor\"].min()\n",
    "    fl_max = df[\"evaluation_flavor\"].max()\n",
    "    bd_min = df[\"evaluation_body\"].min()\n",
    "    bd_max = df[\"evaluation_body\"].max()\n",
    "    cr_min = df[\"evaluation_crema\"].min()\n",
    "    cr_max = df[\"evaluation_crema\"].max()\n",
    "    gen_min = df[\"evaluation_general\"].min()\n",
    "    gen_max = df[\"evaluation_general\"].max()\n",
    "\n",
    "    noise = {}\n",
    "    for i in range(4):\n",
    "        noise[i] = np.random.choice([-0.5, 0, 0.5], df.shape[0], p = [0.25, 0.5, 0.25])\n",
    "\n",
    "    df[\"evaluation_flavor\"] = ((df[\"evaluation_flavor\"] - fl_min) / (fl_max - fl_min)) * 10 + noise[0]\n",
    "    df[\"evaluation_body\"] = ((df[\"evaluation_body\"] - bd_min) / (bd_max - bd_min)) * 10 + noise[1]\n",
    "    df[\"evaluation_crema\"] = ((df[\"evaluation_crema\"] - cr_min) / (cr_max - cr_min)) * 10 + noise[2]\n",
    "    df[\"evaluation_general\"] = ((df[\"evaluation_general\"] - gen_min) / (gen_max - gen_min)) * 10 + noise[3]\n",
    "\n",
    "    df[\"evaluation_flavor\"] = df[\"evaluation_flavor\"].round(0).clip(1, 10).astype(int)\n",
    "    df[\"evaluation_body\"] = df[\"evaluation_body\"].round(0).clip(1, 10).astype(int)\n",
    "    df[\"evaluation_crema\"] = df[\"evaluation_crema\"].round(0).clip(1, 10).astype(int)\n",
    "    df[\"evaluation_general\"] = df[\"evaluation_general\"].round(0).clip(1, 10).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe05c95",
   "metadata": {},
   "source": [
    "Applying these three functions, the dataframe is extended with evaluation columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c5ef6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_espresso_samples = create_eval_cols(df_coffee_samples.copy())\n",
    "df_espresso_samples = extra_flavor(df_espresso_samples.copy())\n",
    "df_espresso_samples = scale_noise_int(df_espresso_samples.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f74ef",
   "metadata": {},
   "source": [
    "With addition of final missing columns, and keeping only the necessary ones in the proper order, the final dataframe is ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "002641c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_espresso_samples[\"water_temp_c\"] = 93\n",
    "df_espresso_samples[\"evaluation_notes\"] = \"\"\n",
    "\n",
    "df_espresso = df_espresso_samples[[\n",
    "    \"id\", \n",
    "    \"experiment_datetime\",\n",
    "    \"user_id\", \n",
    "    \"coffee_machine_id\", \n",
    "    \"grinder_id\", \n",
    "    \"basket_pressurized\",\n",
    "    \"basket_shot_size\",\n",
    "    \"portafilter_spout\",\n",
    "    \"wdt_used\",\n",
    "    \"tamping_method\",\n",
    "    \"tamping_weight_kg\",\n",
    "    \"leveler_used\",\n",
    "    \"puck_screen_used\",\n",
    "    \"puck_screen_thickness_mm\",\n",
    "    \"coffee_bean_purchase_id\",\n",
    "    \"grind_setting\",\n",
    "    \"dose_gr\",\n",
    "    \"water_temp_c\",\n",
    "    \"extraction_time_sec\",\n",
    "    \"yield_gr\",\n",
    "    \"evaluation_general\", \n",
    "    \"evaluation_flavor\",\n",
    "    \"evaluation_body\", \n",
    "    \"evaluation_crema\",\n",
    "    \"evaluation_notes\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf708be8",
   "metadata": {},
   "source": [
    "## Write dataframes to the database\n",
    "\n",
    "Finally, these 8 dataframes can be written to the database. It is assumed here that the database with corresponding schema exists, and there is a known user with at least appending privileges (`INSERT INTO`). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc6673",
   "metadata": {},
   "source": [
    "Libraries for database connection, and reading info from dotenv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7c445bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlmodel import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07608eb9",
   "metadata": {},
   "source": [
    "Set up database connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89e000fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "driver = os.getenv(\"DB_DRIVER\")\n",
    "connector = os.getenv(\"DB_CONNECTOR\")\n",
    "user = os.getenv(\"DB_USERNAME\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "port = os.getenv(\"DB_PORT\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "db_path = f\"{driver}+{connector}://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "db_engine = create_engine(db_path, echo = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf6836",
   "metadata": {},
   "source": [
    "Send data to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.to_sql(\"Users\", db_engine, if_exists = \"append\", index = False)\n",
    "df_coffee_machines.to_sql(\"CoffeeMachines\", db_engine, if_exists = \"append\", index = False)\n",
    "df_grinders.to_sql(\"Grinders\", db_engine, if_exists = \"append\", index = False)\n",
    "df_equipment.to_sql(\"EquipmentOwnership\", db_engine, if_exists = \"append\", index = False)\n",
    "df_defaults.to_sql(\"UserDefaults\", db_engine, if_exists = \"append\", index = False)\n",
    "df_variety.to_sql(\"CoffeeBeanVarieties\", db_engine, if_exists = \"append\", index = False)\n",
    "df_purchase.to_sql(\"CoffeeBeanPurchases\", db_engine, if_exists = \"append\", index = False)\n",
    "df_espresso.to_sql(\"EspressoExperiments\", db_engine, if_exists = \"append\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espresso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
